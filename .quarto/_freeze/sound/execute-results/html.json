{
  "hash": "8ac1a8d5ff374a526b16bd903e2850ac",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: <font size=\"7\"><b>Sound</b></font>\neditor_options: \n  chunk_output_type: console\n---\n\n\n \n\n::: {.alert .alert-info}\n## **Objetives** {.unnumbered .unlisted}\n\n-   Learn the basic aspects of sound as a physical phenomenom\n\n-   Get familiar with how sound is represented as a digital object in R\n:::\n\n \n\n\n::: {.cell}\n\n:::\n\n\n \n\nSound waves are characterized by compression and expansion of the medium as sound energy moves through it. There is also back and forth motion of the particles making up the medium:\n\n<img src=\"images/wave_white_bg.gif\" alt=\"wave animation\" width=\"700\"/>\n\n<font size=\"3\"> taken from https://dosits.org</font>\n\n \n\nThe variation in pressure that is perceived at a fixed point in space can be represented by a graph of pressure (amplitude) by time:\n\n![wave and oscillogram](images/amplitude.gif){width=\"600\" height=\"350\"}\n\n \n\nSounds waves are typically quantified by their frequency (number of cycles per second, Hz) and amplitude (relative intensity).\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](sound_files/figure-html/unnamed-chunk-2-1.png){width=85%}\n:::\n:::\n\n\n \n\n::: {.alert .alert-success}\n<font size=\"6\"><b>Digitizing sound</b></font>\n\n \n\n## Sampling frequency\n\nDigitizing implies discretizing, which requires some sort of regular sampling. Sampling frequency refers to how many samples of the pressure level of the environment are taken per second. A 440 Hz sine wave recorded at 44100 Hz would have around 100 samples per cycle. This plot shows 2 cycles of a 440 Hz sine wave sampled (vertical dotted lines) at 4410 Hz (a 1/10 of the recording sampling rate):\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](sound_files/figure-html/unnamed-chunk-3-1.png){width=100%}\n:::\n:::\n\n\n## Nyquist frequency\n\nSampling should be good enough so the regularity of the sine wave can be reconstructed from the sampled data. Low sampling frequencies of a high frequency sine wave might not be able to provide enough information. For instance, the same 440 Hz sine wave sampled at 22050 Hz looks like this:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](sound_files/figure-html/unnamed-chunk-4-1.png){width=100%}\n:::\n:::\n\n\n \n\nAs you can see way less samples are taken per unit of time. The threshold at which samples cannot provide a reliable estimate of the regularity of a sine wave is called **Nyquist frequency** and corresponds to half of the frequency of the sine wave. This is how the 2 cycles of the 440 Hz would look like when sampled at its Nyquist frequency (sampling frequency of 880 Hz):\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](sound_files/figure-html/unnamed-chunk-5-1.png){width=100%}\n:::\n:::\n\n\n \n\n## Quantization\n\nOnce we know at which point amplitude samples will be taken we just need to measure it. This process is called **quantization**. The range of amplitude values is discretized in a number of intervals equals to `2 ^ bits`. Hence, it involves some rounding of the actual amplitude values and some data loss. This is the same 440 Hz sine wave recorded at 44100 kHz quantized at 2 bits (2\\^2 = 4 intervals):\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](sound_files/figure-html/unnamed-chunk-6-1.png){width=100%}\n:::\n:::\n\n\n \n\nRounding and data loss is more obvious if we add lines to the sampled points:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](sound_files/figure-html/unnamed-chunk-7-1.png){width=100%}\n:::\n:::\n\n\n \n\nThis is the same signal quantized at 3 bits (2\\^3 = 8 intervals):\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](sound_files/figure-html/unnamed-chunk-8-1.png){width=100%}\n:::\n:::\n\n\n \n\n4 bits (2\\^4 = 16 intervals):\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](sound_files/figure-html/unnamed-chunk-9-1.png){width=100%}\n:::\n:::\n\n\n \n\n.. and 8 bits (2\\^8 = 256 intervals):\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](sound_files/figure-html/unnamed-chunk-10-1.png){width=100%}\n:::\n:::\n\n\n \n\nAt this point quantization involves very little information loss. 16 bits is probably the most common dynamic range used nowadays. As you can imagine, the high number of intervals (2\\^16 = 65536) allows for great precision in the quantization of amplitude.\n:::\n\n \n\n# Sound in R\n\nSound waves can be represented by 3 kinds of R objects:\n\n-   Common classes (numerical vector, numerical matrix)\n-   Time series classes (ts, mts)\n-   Specific sound classes (Wave, sound and audioSample)\n\n \n\n## Non-specific classes\n\n### Vectors\n\nAny numerical vector can be treated as a sound if a sampling frequency is provided. For example, a 440 Hz sinusoidal sound sampled at 8000 Hz for one second can be generated like this:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(seewave)\n\n# create sinewave at 440 Hz\ns1 <- sin(2 * pi * 440 * seq(0, 1, length.out = 8000))\n\nis.vector(s1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] TRUE\n```\n\n\n:::\n\n```{.r .cell-code}\nmode(s1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"numeric\"\n```\n\n\n:::\n:::\n\n\n \n\nThese sequences of values only make sense when specifying the sampling rate at which they were created:\n\n\n::: {.cell}\n\n```{.r .cell-code}\noscillo(s1, f = 8000, from = 0, to = 0.01)\n```\n\n::: {.cell-output-display}\n![](sound_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n \n\n### Matrices\n\nYou can read any single column matrix:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns2 <- as.matrix(s1)\n\nis.matrix(s2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] TRUE\n```\n\n\n:::\n\n```{.r .cell-code}\ndim(s2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 8000    1\n```\n\n\n:::\n\n```{.r .cell-code}\noscillo(s2, f = 8000, from = 0, to = 0.01)\n```\n\n::: {.cell-output-display}\n![](sound_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n \n\nIf the matrix has more than one column, only the first column will be considered:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- rnorm(8000)\n\ns3 <- cbind(s2, x)\n\nis.matrix(s3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] TRUE\n```\n\n\n:::\n\n```{.r .cell-code}\ndim(s3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 8000    2\n```\n\n\n:::\n\n```{.r .cell-code}\noscillo(s3, f = 8000, from = 0, to = 0.01)\n```\n\n::: {.cell-output-display}\n![](sound_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n \n\n### Time series\n\nThe class `ts` and related functions `ts()`, `as.ts()`, `is.ts()` can also be used to generate sound objects in R. Here the command to similarly generate a series of time is shown corresponding to a 440 Hz sinusoidal sound sampled at 8000 Hz for one second:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns4 <- ts(data = s1, start = 0, frequency = 8000)\n\nstr(s4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Time-Series [1:8000] from 0 to 1: 0 0.339 0.637 0.861 0.982 ...\n```\n\n\n:::\n:::\n\n\n \n\nTo generate a random noise of 0.5 seconds:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns4 <- ts(data = runif(4000, min = -1, max = 1), start = 0, end = 0.5, frequency = 8000)\n\nstr(s4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Time-Series [1:4001] from 0 to 0.5: 0.551 -0.744 0.535 0.182 0.547 ...\n```\n\n\n:::\n:::\n\n\n \n\nThe `frequency()` and `deltat()` functions return the sampling frequency ($f$) and the time resolution ($Delta t$) respectively:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfrequency(s4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 8000\n```\n\n\n:::\n\n```{.r .cell-code}\ndeltat(s4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.000125\n```\n\n\n:::\n:::\n\n\n \n\nAs the frequency is incorporated into the `ts` objects, it is not necessary to specify it when used within functions dedicated to audio:\n\n\n::: {.cell}\n\n```{.r .cell-code}\noscillo(s4, from = 0, to = 0.01)\n```\n\n::: {.cell-output-display}\n![](sound_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\n \n\nIn the case of multiple time series, **seewave** functions will consider only the first series:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns5 <- ts(data = s3, f = 8000)\n\nclass(s5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"mts\"    \"ts\"     \"matrix\" \"array\" \n```\n\n\n:::\n\n```{.r .cell-code}\noscillo(s5, from = 0, to = 0.01)\n```\n\n::: {.cell-output-display}\n![](sound_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\n## Dedicated R classes for sound\n\nThere are 3 kinds of objects corresponding to the `wav` binary format or the`mp3` compressed format:\n\n-   `Wave` class of the package **tuneR**\n-   `sound` class of the package **phonTools**\n-   `AudioSample` class of the package **audio**\n\n \n\n### `Wave` class (**tuneR**)\n\nThe `Wave` class comes with the **tuneR** package. This S4 class includes different \"slots\" with the amplitude data (left or right channel), the sampling frequency (or frequency), the number of bits (8/16/24/32) and the type of sound (mono/stereo). High sampling rates (\\> 44100 Hz) can be read on these types of objects.\n\nThe function to import `.wav` files from the hard drive is `readWave`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load packages\nlibrary(tuneR)\n\ns6 <- readWave(\"./examples/Phae.long1.wav\")\n```\n:::\n\n\n \n\nWe can verify the class of the object like this:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# object class\nclass(s6)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Wave\"\nattr(,\"package\")\n[1] \"tuneR\"\n```\n\n\n:::\n:::\n\n\n \n\nS4 objects have a structure similar to lists but use '\\@' to access each position (slot):\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# structure\nstr(s6)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nFormal class 'Wave' [package \"tuneR\"] with 6 slots\n  ..@ left     : int [1:56251] 162 -869 833 626 103 -2 43 19 47 227 ...\n  ..@ right    : num(0) \n  ..@ stereo   : logi FALSE\n  ..@ samp.rate: int 22500\n  ..@ bit      : int 16\n  ..@ pcm      : logi TRUE\n```\n\n\n:::\n\n```{.r .cell-code}\n# extract 1 position\ns6@samp.rate\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 22500\n```\n\n\n:::\n:::\n\n\n \n\n::: {.alert .alert-warning}\n\"Pulse-code modulation (PCM) is a method used to digitally represent sampled analog signals. It is the standard form of digital audio. In a PCM stream, the amplitude of the analog signal is sampled regularly at uniform intervals, and each sample is quantized to the nearest value within a range of digital steps\" ([Wikipedia](https://en.wikipedia.org/wiki/Pulse-code_modulation)).\n:::\n\n \n\nThe samples come in the slot '@left':\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# samples\ns6@left[1:40]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1]  162 -869  833  626  103   -2   43   19   47  227   -4  205  564  171  457\n[16]  838 -216   60   76 -623 -213  168 -746 -248  175 -512  -58  651  -85 -213\n[31]  586   40 -407  371  -51 -587  -92   94 -527   40\n```\n\n\n:::\n:::\n\n\n \n\nThe number of samples is given by the duration and the sampling rate.\n\n \n\n::: {.alert .alert-info}\n<font size=\"5\">Exercise</font>\n\n-   How can we calculate the duration of the `wave` object using the information in the object?\n\n \n\n-   Extract the first second of audio from the object `s6` using indexing (and squared brackets)\n:::\n\n \n\nAn advantage of using `readWave()` is the ability to read specific segments of sound files, especially useful with long files. This is done using the `from` and`to` arguments and specifying the units of time with the `units` arguments. The units can be converted into \"samples\", \"minutes\" or \"hours\". For example, to read only the section that begins in 1s and ends in 2s of the file \"Phae.long1.wav\":\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns7 <- readWave(\"./examples/Phae.long1.wav\", from = 1, to = 2, units = \"seconds\")\n\ns7\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nWave Object\n\tNumber of Samples:      22500\n\tDuration (seconds):     1\n\tSamplingrate (Hertz):   22500\n\tChannels (Mono/Stereo): Mono\n\tPCM (integer format):   TRUE\n\tBit (8/16/24/32/64):    16 \n```\n\n\n:::\n:::\n\n\n \n\nThe `.mp3` files can be imported to R although they are imported in`Wave` format. This is done using the `readMP3()` function:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns7 <- readMP3(\"./examples/Phae.long1.mp3\")\n\ns7\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nWave Object\n\tNumber of Samples:      56448\n\tDuration (seconds):     2.56\n\tSamplingrate (Hertz):   22050\n\tChannels (Mono/Stereo): Mono\n\tPCM (integer format):   TRUE\n\tBit (8/16/24/32/64):    16 \n```\n\n\n:::\n:::\n\n\n \n\nTo obtain information about the object (sampling frequency, number of bits, mono/stereo), it is necessary to use the indexing of S4 class objects:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns7@samp.rate\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 22050\n```\n\n\n:::\n\n```{.r .cell-code}\ns7@bit\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 16\n```\n\n\n:::\n\n```{.r .cell-code}\ns7@stereo\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] FALSE\n```\n\n\n:::\n:::\n\n\n \n\nA property that does not appear in these calls is that `readWave` does not normalize the sound. The values that describe the sound will be included between $\\pm2^{bit} - 1$:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrange(s7@left)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -32768  32767\n```\n\n\n:::\n:::\n\n\n \n\n::: {.alert .alert-info}\n<font size=\"5\">Exercise</font>\n\nThe function `Wave` can be used to create wave objects.\n\n \n\n-   Run the example code in the function documentation\n\n-   Plot the oscillogram for the first 0.01 s of 'Wobj'\n\n-   Note that the function `sine` provides a shortcut that can be used to create wave object with a sine wave. Check out other similar functions described in the `sine` function documentation. Try 4 of these alternative functions and plot the oscillogram of the first 0.01 s for each of them.\n:::\n\n \n\nThe function `read_sound_files` from warbleR is a wrapper over several sound file reading functions, that can read files in 'wav', 'mp3', 'flac' and 'wac' format:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(warbleR)\n\n# wave\nrsf1 <- read_sound_file(\"Phaethornis-eurynome-15607.wav\", path = \"./examples\")\n\nclass(rsf1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Wave\"\nattr(,\"package\")\n[1] \"tuneR\"\n```\n\n\n:::\n\n```{.r .cell-code}\n# mp3\nrsf2 <- read_sound_file(\"Phaethornis-striigularis-154074.mp3\", path = \"./examples\")\n\nclass(rsf2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Wave\"\nattr(,\"package\")\n[1] \"tuneR\"\n```\n\n\n:::\n\n```{.r .cell-code}\n# flac\nrsf3 <- read_sound_file(\"Phae.long1.flac\", path = \"./examples\")\n\nclass(rsf3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Wave\"\nattr(,\"package\")\n[1] \"tuneR\"\n```\n\n\n:::\n\n```{.r .cell-code}\n# wac\nrsf4 <- read_sound_file(\"recording_20170716_230503.wac\", path = \"./examples\")\n\nclass(rsf4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Wave\"\nattr(,\"package\")\n[1] \"tuneR\"\n```\n\n\n:::\n:::\n\n\n \n\nThe function can also read recordings hosted in an online repository:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrsf5 <- read_sound_file(X = \"https://xeno-canto.org/35340/download\")\n\nclass(rsf5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Wave\"\nattr(,\"package\")\n[1] \"tuneR\"\n```\n\n\n:::\n\n```{.r .cell-code}\nrsf6 <- read_sound_file(X = \"https://github.com/maRce10/OTS_BIR_2024/raw/master/examples/Phae.long1.flac\")\n\nclass(rsf6)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Wave\"\nattr(,\"package\")\n[1] \"tuneR\"\n```\n\n\n:::\n:::\n\n\n \n\n## Class `sound` (**phonTools**)\n\nThe `loadsound()` function of *phonTools* also imports 'wave' sound files into R, in this case as objects of class `sound`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(phonTools)\n\ns8 <- loadsound(\"./examples/Phae.long1.wav\")\n\ns8\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n      Sound Object\n\n   Read from file:         ./examples/Phae.long1.wav\n   Sampling frequency:     22500  Hz\n   Duration:               2500.044  ms\n   Number of Samples:      56251 \n```\n\n\n:::\n\n```{.r .cell-code}\nstr(s8)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nList of 5\n $ filename  : chr \"./examples/Phae.long1.wav\"\n $ fs        : int 22500\n $ numSamples: num 56251\n $ duration  : num 2500\n $ sound     : Time-Series [1:56251] from 0 to 2.5: 0.00494 -0.02652 0.02542 0.0191 0.00314 ...\n - attr(*, \"class\")= chr \"sound\"\n```\n\n\n:::\n:::\n\n\n \n\nThis function only imports files with a dynamic range of 8 or 16 bits.\n\n \n\n## Class `audioSample` (**audio**)\n\nThe **audio** package is another option to handle `.wav` files. The sound can be imported using the `load.wave()` function. The class of the resulting object is `audioSample` which is essentially a numerical vector (for mono) or a numerical matrix with two rows (for stereo). The sampling frequency and resolution are saved as attributes:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(audio)\n\ns10 <- load.wave(\"./examples/Phae.long1.wav\")\n\nhead(s10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nsample rate: 22500Hz, mono, 16-bits\n[1]  4.943848e-03 -2.652058e-02  2.542114e-02  1.910400e-02  3.143311e-03\n[6] -6.103702e-05\n```\n\n\n:::\n\n```{.r .cell-code}\ns10$rate\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 22500\n```\n\n\n:::\n\n```{.r .cell-code}\ns10$bits\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 16\n```\n\n\n:::\n:::\n\n\n \n\nThe main advantage of the **audio** package is that the sound can be acquired directly within an R session. This is achieved first by preparing a `NAs` vector and then using the`record()` function. For example, to obtain a mono sound of 5 seconds sampled at 16 kHz:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns11 <- rep(NA_real_, 16000 * 5)\n\nrecord(s11, 16000, 1)\n```\n:::\n\n\n \n\nA recording session can be controlled by three complementary functions: `pause()`, `rewind()`, and `resume()`.\n\n \n\n## Export sounds from R\n\nFor maximum compatibility with other sound programs, it may be useful to save a sound as a simple `.txt` file. The following commands will write a \"tico.txt\" file:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(tico)\n\nexport(tico, f = 22050)\n```\n:::\n\n\n \n\n## Format '.wav'\n\n**tuneR** and **audio** have a function to write `.wav` files: `writeWave()` and `save.wave()` respectively. Within **seewave**, the `savewav()` function, which is based on `writeWave()`, can be used to save data in `.wav` format. By default, the object name will be used for the name of the `.wav` file:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsavewav(tico)\n```\n:::\n\n\n \n\n## Format '.flac'\n\nFree Lossless Audio Codec (FLAC) is a file format for lossless audio data compression. FLAC reduces bandwidth and storage requirements without sacrificing the integrity of the audio source. Audio sources encoded in FLAC are generally reduced in size from 40 to 50 percent. See the flac website for more details ([flac.sourceforge.net](http://flac.sourceforge.net)).\n\nThe `.flac` format cannot be used as such with R. However, the `wav2flac()`function allows you to call the FLAC software directly from the console. Therefore, FLAC must be installed on your operating system. If you have a `.wav` file that you want to compress in `.flac`, call:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwav2flac(file = \"./examples/Phae.long1.wav\", overwrite = FALSE)\n```\n:::\n\n\n \n\nTo compress a `.wav` file to a `.flac` format, the argument `reverse = TRUE` must be used:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwav2flac(\"Phae.long1.flac\", reverse = TRUE)\n```\n:::\n\n\n \n\nThis table, taken from Sueur (2018), summarizes the functions available to import and export sound files in R. The table is incomplete since it does not mention the functions of the `phonTools` package:\n\n<img src=\"images/tabla-waves.png\" alt=\"tabla imp exp waves\" width=\"700\"/>\n\n------------------------------------------------------------------------\n\n \n\n::: {.alert .alert-info}\n<font size=\"5\">Exercise</font>\n\n-   How does the sampling rate affect the size of an audio file? (hint: create 2 sounds files with the same data but different sampling rates; use `sine()`)\n\n-   How does the dynamic range affect the size of an audio file?\n\n-   Use the `system.time()` function to compare the performance of the different functions to import audio files in R. For this use the file \"LBH.374.SUR.wav\" (Long-billed hermit songs) which lasts about 2 min\n\nThe following code creates a plot similar to `oscillo` but using dots instead of lines:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# generate sine wave\nwav <- sine(freq = 440, duration = 500, xunit = \"samples\", samp.rate = 44100)\n\n# plot\nplot(wav@left)\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](sound_files/figure-html/unnamed-chunk-38-1.png){width=672}\n:::\n:::\n\n\n \n\n-   Use the function `downsample()` to reduce the sampling rate of 'wav' (below 44100) and plot the output object. Decrease the sampling rate until you cannot recognize the wave pattern from the original wave object. Try several values so you get a sense at which sampling rate this happens.\n\n\n::: {.cell}\n\n:::\n\n:::\n\n \n\n------------------------------------------------------------------------\n\n## References\n\n1.  Sueur J, Aubin T, Simonis C. 2008. Equipment review: seewave, a free modular tool for sound analysis and synthesis. Bioacoustics 18(2):213--226.\n\n2.  Sueur, J. (2018). Sound Analysis and Synthesis with R.\n\n3.  Sueur J. (2018). I/O of sound with R. seewave package vignette. url: https://cran.r-project.org/web/packages/seewave/vignettes/seewave_IO.pdf\n\n------------------------------------------------------------------------\n\n<font size=\"4\">Session information</font>\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\nR version 4.4.1 (2024-06-14)\nPlatform: x86_64-pc-linux-gnu\nRunning under: Ubuntu 22.04.4 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.10.0 \nLAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.10.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=es_CR.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=es_CR.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=es_CR.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=es_CR.UTF-8 LC_IDENTIFICATION=C       \n\ntime zone: America/Costa_Rica\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] audio_0.1-11       phonTools_0.2-2.2  warbleR_1.1.32     NatureSounds_1.0.4\n[5] tuneR_1.4.7        knitr_1.48         seewave_2.2.3     \n\nloaded via a namespace (and not attached):\n [1] viridis_0.6.5      utf8_1.2.4         generics_0.1.3     bitops_1.0-9      \n [5] stringi_1.8.4      digest_0.6.37      magrittr_2.0.3     evaluate_1.0.0    \n [9] grid_4.4.1         fastmap_1.2.0      jsonlite_1.8.9     brio_1.1.5        \n[13] formatR_1.14       gridExtra_2.3      fansi_1.0.6        viridisLite_0.4.2 \n[17] scales_1.3.0       pbapply_1.7-2      cli_3.6.3          rlang_1.1.4       \n[21] fftw_1.0-9         munsell_0.5.1      withr_3.0.1        yaml_2.3.10       \n[25] tools_4.4.1        parallel_4.4.1     dplyr_1.1.4        colorspace_2.1-1  \n[29] ggplot2_3.5.1      bioacoustics_0.2.8 vctrs_0.6.5        R6_2.5.1          \n[33] proxy_0.4-27       lifecycle_1.0.4    dtw_1.23-1         stringr_1.5.1     \n[37] htmlwidgets_1.6.4  MASS_7.3-61        pkgconfig_2.0.3    pillar_1.9.0      \n[41] gtable_0.3.5       moments_0.14.1     glue_1.8.0         Rcpp_1.0.13       \n[45] xfun_0.48          tibble_3.2.1       tidyselect_1.2.1   rstudioapi_0.16.0 \n[49] rjson_0.2.23       htmltools_0.5.8.1  rmarkdown_2.28     testthat_3.2.1.1  \n[53] signal_1.8-1       compiler_4.4.1     RCurl_1.98-1.16   \n```\n\n\n:::\n:::\n",
    "supporting": [
      "sound_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}